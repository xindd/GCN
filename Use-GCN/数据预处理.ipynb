{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio.KEGG.REST import *\n",
    "from Bio.KEGG.KGML import KGML_parser\n",
    "from Bio.Graphics.KGML_vis import KGMLCanvas\n",
    "from Bio.Graphics.ColorSpiral import ColorSpiral\n",
    "\n",
    "from IPython.display import Image, HTML\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import networkx as nx\n",
    "from networkx import to_numpy_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth',500) # 设置DataFrame显示的宽度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取 pathway，保存 pathway 节点\n",
    "def extract_pathways_nodes(species='hsa', path='data/', save=True):\n",
    "    print('Executing function extract_pathways_nodes:')\n",
    "    pathway_nodes = kegg_list('pathway', species).read()\n",
    "    pathway_nodes_df = pd.read_csv(StringIO(pathway_nodes), sep='\\t', header=None)\n",
    "    if save:\n",
    "        print('--- save pathway nodes to %s ...' % (path + 'pathway_nodes.csv'))\n",
    "        pathway_nodes_df[0].to_csv(path + 'pathway_nodes.csv', header=0, index=0)\n",
    "        print('--- save pathway annotate to %s ...' % (path + 'pathway_nodes_annotate.csv'))\n",
    "        pathway_nodes_df.to_csv(path + 'pathway_nodes_annotate.csv', header=0, index=0)\n",
    "    return pathway_nodes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解析 xml 文件\n",
    "# 1. 提取 pathway--pathway 关系\n",
    "# 2. 提取每个 pathway 下 entry_nodes\n",
    "#    A. 提取 entry--entry 关系\n",
    "#    B. 提取 entry--gene 对应关系\n",
    "#    C. 提取 entry nodes\n",
    "\n",
    "def parser_xml(pathway_nodes_df, save=True):\n",
    "    print('Executing function parser_xml:')\n",
    "    pathwaylist = list(pathway_nodes_df[0]) # 获取 pathway 列表\n",
    "    enzymeDict = {} # 初始化结果字典\n",
    "    path2path = list() # 初始化 \n",
    "    procress, allnum = 0, len(pathwaylist) # 显示进度\n",
    "    \n",
    "    for pathwayname in pathwaylist:\n",
    "        if procress % (allnum//5) == 0:\n",
    "            print(f\"--- Parsing xml {procress}/{allnum} pathwayname: {pathwayname}\")\n",
    "        procress += 1\n",
    "        # 在线提取 pathwayname 下的 xml 文件\n",
    "        pathway2xml = KGML_parser.read(kegg_get(pathwayname, \"kgml\"))\n",
    "        # 将 xml 内出现的所有 map 类型保存，并认为这些 map 与 pathwayname 有互作关系\n",
    "        path2path.extend([[pathwayname, maps.name] for maps in pathway2xml.maps if maps.name in pathwaylist])\n",
    "        # 设置空的 dataframe 存储 pathwayname 下 entry 与 entry 关系\n",
    "        relation2entry = pd.DataFrame(columns=('id1', 'id2'))\n",
    "        genelist = pathway2xml.genes\n",
    "        for i, gene in enumerate(pathway2xml.relations):\n",
    "            if gene.entry1 in genelist and gene.entry2 in genelist:\n",
    "                relation2entry.loc[i,:] = [pathwayname+'_'+str(gene.entry1.id), pathwayname+'_'+str(gene.entry2.id)]\n",
    "        \n",
    "        entry_nodes = list(set(relation2entry['id1'].tolist()+relation2entry['id2'].tolist()))\n",
    "        id2gene = [(pathwayname+'_'+str(gene.id), gene.name) for gene in genelist]\n",
    "        enzymeDict[pathwayname] = {'entry_nodes': entry_nodes, 'entry_entry_edges': relation2entry, 'entry2gene': id2gene}\n",
    "    print('--- Finish parsing xml')\n",
    "    print('--- Processing data...')\n",
    "    # 去重\n",
    "    path2path = pd.DataFrame(path2path, columns=('path1', 'path2'))\n",
    "    rows=[i for i in path2path.index if path2path.iat[i,0]==path2path.iat[i,1]]\n",
    "    path2path2=path2path.drop(rows,axis=0) #利用drop方法将含 path1=path2 的行删除\n",
    "    path2path2 = path2path2.drop_duplicates(['path1', 'path2'], keep='first') # 删除重复行\n",
    "    a=path2path2.apply(lambda x: str(sorted(x.tolist())), axis=1)\n",
    "    pos = pd.DataFrame(a).duplicated()\n",
    "    path2path_drop = path2path2.loc[-pos,:].reset_index()\n",
    "    # 保存\n",
    "    if save:\n",
    "        print('--- Saving data pathway2enzyme.pickle.txt')\n",
    "        with open('data/pathway2enzyme.pickle.txt','wb') as file:\n",
    "            pickle.dump(enzymeDict,file)\n",
    "        print('--- Saving data pathway2pathway.csv')\n",
    "        path2path_drop[['path1', 'path2']].to_csv('data/pathway2pathway.csv', header=0, index=0)\n",
    "    return {'pathway2enzyme': enzymeDict, 'pathway2pathway': path2path_drop}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将 hsa 与 gene symbol 对应\n",
    "def hsa2symbol(hgncPath, ppiPath, enzymeDict,save=True):\n",
    "    print('Executing function hsa2symbol:')\n",
    "    allgene = []\n",
    "    for path in list(enzymeDict.keys()):\n",
    "        for gene in enzymeDict[path]['entry2gene']:\n",
    "            allgene.extend(gene[1].split(' '))\n",
    "    allgene_drop = list(set(allgene))\n",
    "    print('--- hsa numbers: %d' % (len(allgene_drop)))\n",
    "    # hgncPath = 'E:/wx/2019上课题/数据/hgnc_complete_set.txt'\n",
    "    hgncFile = pd.read_csv(hgncPath, sep='\\t',\n",
    "                           usecols=['hgnc_id', 'symbol', 'name', 'alias_symbol', 'entrez_id',\n",
    "                                    'ensembl_gene_id', 'uniprot_ids', 'enzyme_id'],\n",
    "                           engine='python', \n",
    "                           dtype={'entrez_id': str})\n",
    "    gene2symbol = hgncFile.loc[hgncFile['entrez_id'].isin([i[4:] for i in allgene_drop])]\n",
    "    # ppiPath = 'E:/wx/2019上课题/数据/9606.protein.info.v11.0.txt'\n",
    "    PPI_gene = pd.read_csv(ppiPath, sep='\\t',\n",
    "                       usecols=['protein_external_id', 'preferred_name'],\n",
    "                       engine='python')\n",
    "    \n",
    "    # 将 xml 提取的 gene 与 蛋白互作数据中的 gene 取交集\n",
    "    finalgene = PPI_gene.loc[PPI_gene['preferred_name'].isin(gene2symbol['symbol'])]\n",
    "    # 提取 hsa:xxx gene 与 symbol 对应关系\n",
    "    hsa2symbol = hgncFile.loc[hgncFile['symbol'].isin(finalgene['preferred_name'])][['symbol', 'entrez_id']]\n",
    "    hsa2symbol['entrez_id'] = hsa2symbol.apply(lambda x: 'hsa:'+str(x[1]), axis=1)\n",
    "    hsa2symbol.reset_index(drop=True)\n",
    "    if save:\n",
    "        print('--- Saving data symbol_nodes.csv')\n",
    "        finalgene['preferred_name'].to_csv('data/symbol_nodes.csv', header=0, index=0)\n",
    "        print('--- Saving data hsa2symbol.csv')\n",
    "        hsa2symbol.to_csv('data/hsa2symbol.csv', header=0, index=0)\n",
    "        print('--- Saving data symbol2protein.csv')\n",
    "        finalgene.to_csv('data/symbol2protein.csv', header=0, index=0)\n",
    "    return {'symbol': finalgene['preferred_name'], 'hsa2symbol': hsa2symbol, 'symbol2protein': finalgene}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用 protein 互作网络提取 symbol 互作网络\n",
    "def ppi2symbols(ppiPath, savePath, symbol2protein):\n",
    "    print('Executing function ppi2symbols:')\n",
    "    protein_ensp_id = list(symbol2protein['protein_external_id'])\n",
    "    proetin_protein = []\n",
    "    # savePath = 'data/protein_protein_edges.csv'\n",
    "    outputfile = open(savePath, 'w')\n",
    "    # ppiPath = 'E:/wx/2019上课题/数据/9606.protein.links.v11.0.txt'\n",
    "    print('--- Running, this may take a long time, please be patient')\n",
    "    with open(ppiPath, 'r') as file:\n",
    "        i = 0\n",
    "        for r in file.readlines():\n",
    "            if i % 500000==0:\n",
    "                print(f'--- {i} lines that have been read')\n",
    "            i += 1\n",
    "            p1, p2, s = r.strip().split(' ')\n",
    "            if p1 in protein_ensp_id and p2 in protein_ensp_id:  \n",
    "                outputfile.write(symbol2protein.loc[symbol2protein.protein_external_id==p1, 'preferred_name'].values[0] + ',' +\n",
    "                                 symbol2protein.loc[symbol2protein.protein_external_id==p2, 'preferred_name'].values[0] + ',' + s + '\\n')\n",
    "    outputfile.close()\n",
    "    print(f'--- Finish, save the file to {savePath}')\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对 symbol 互作网络去重\n",
    "def ppi2duplicated(ppiPath):\n",
    "    print('Executing function ppi2duplicated:')\n",
    "    #ppiPath = 'data/protein_protein_edges.csv'\n",
    "    PPI = pd.read_csv(ppiPath, sep=',',\n",
    "                      names =['p1','p2', 'score'],\n",
    "                      header=None,\n",
    "                      engine='python')\n",
    "    sortppi = PPI[['p1', 'p2']].apply(lambda x: str(sorted(x.tolist())), axis=1)\n",
    "    pos = pd.DataFrame(sortppi).duplicated()\n",
    "    ppi_drop = PPI.loc[-pos,:].reset_index()\n",
    "    ppi_drop = ppi_drop[['p1','p2', 'score']]\n",
    "    # savePath = 'data/protein_protein_edges_drop_duplicated.csv'\n",
    "    print('--- Saving data protein_protein_edges.csv')\n",
    "    ppi_drop.to_csv('data/protein_protein_edges.csv', header=0, index=0)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing function extract_pathways_nodes:\n",
      "--- save pathway nodes to data/pathway_nodes.csv ...\n",
      "--- save pathway annotate to data/pathway_nodes_annotate.csv ...\n",
      "Executing function parser_xml:\n",
      "--- Parsing xml 0/333 pathwayname: path:hsa00010\n",
      "--- Parsing xml 66/333 pathwayname: path:hsa00650\n",
      "--- Parsing xml 132/333 pathwayname: path:hsa04114\n",
      "--- Parsing xml 198/333 pathwayname: path:hsa04713\n",
      "--- Parsing xml 264/333 pathwayname: path:hsa05033\n",
      "--- Parsing xml 330/333 pathwayname: path:hsa05414\n",
      "--- Finish parsing xml\n",
      "--- Processing data...\n",
      "--- Saving data pathway2enzyme.pickle.txt\n",
      "--- Saving data pathway2pathway.csv\n",
      "Executing function hsa2symbol:\n",
      "--- hsa numbers: 7878\n",
      "--- Saving data symbol_nodes.csv\n",
      "--- Saving data hsa2symbol.csv\n",
      "--- Saving data symbol2protein.csv\n",
      "Executing function ppi2symbols:\n",
      "--- Running, this may take a long time, please be patient\n",
      "--- 0 lines that have been read\n",
      "--- 500000 lines that have been read\n",
      "--- 1000000 lines that have been read\n",
      "--- 1500000 lines that have been read\n",
      "--- 2000000 lines that have been read\n",
      "--- 2500000 lines that have been read\n",
      "--- 3000000 lines that have been read\n",
      "--- 3500000 lines that have been read\n",
      "--- 4000000 lines that have been read\n",
      "--- 4500000 lines that have been read\n",
      "--- 5000000 lines that have been read\n",
      "--- 5500000 lines that have been read\n",
      "--- 6000000 lines that have been read\n",
      "--- 6500000 lines that have been read\n",
      "--- 7000000 lines that have been read\n",
      "--- 7500000 lines that have been read\n",
      "--- 8000000 lines that have been read\n",
      "--- 8500000 lines that have been read\n",
      "--- 9000000 lines that have been read\n",
      "--- 9500000 lines that have been read\n",
      "--- 10000000 lines that have been read\n",
      "--- 10500000 lines that have been read\n",
      "--- 11000000 lines that have been read\n",
      "--- 11500000 lines that have been read\n",
      "--- Finish, save the file to data/protein_protein_edges_duplicated.csv\n",
      "Executing function ppi2duplicated:\n",
      "--- Saving data protein_protein_edges.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    pathwaylist = extract_pathways_nodes()\n",
    "    parser_res=parser_xml(pathway_nodes_df=pathwaylist)\n",
    "\n",
    "    hgncPath = 'E:/wx/2019上课题/数据/hgnc_complete_set.txt'\n",
    "    ppiPath = 'E:/wx/2019上课题/数据/9606.protein.info.v11.0.txt'\n",
    "    res = hsa2symbol(hgncPath=hgncPath, ppiPath=ppiPath, enzymeDict=parser_res['pathway2enzyme'])\n",
    "\n",
    "    savePath = 'data/protein_protein_edges_duplicated.csv'\n",
    "    ppiPath = 'E:/wx/2019上课题/数据/9606.protein.links.v11.0.txt'\n",
    "    ppi2symbols(ppiPath, savePath, symbol2protein=res['symbol2protein'])\n",
    "\n",
    "    ppiPath = 'data/protein_protein_edges_duplicated.csv'\n",
    "    ppi2duplicated(ppiPath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
